{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3330574e-8e60-4274-860c-ab17b2b2e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fef1e2f-0787-4b9b-8aef-03a076c15186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (_,_) = mnist.load_data()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de9a873-a8d4-46a8-8c94-621f7d974869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img parameters\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "z_dim = 28*28 # 생성자의 입력으로 사용할 잡음 벡터의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6edb4a31-03e4-4f4d-a650-8f4529d1cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making Generator\n",
    "\n",
    "def build_generator(z_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256 * 8 * 8, input_dim=z_dim)) # Dense 를 이용해 입력(Z)를 7 * 7 * 256 크기의 텐서로 변환\n",
    "    model.add(Reshape((8,8,256)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')) # 8*8*256 에서 16*16*128 크기의 텐서로 바꾸는 전치 합성곱 층\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')) # 16*16*128 에서 16*16*64 텐서로 바꾸는 전치 합성곱 층\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same')) # strides : 2 16*16*64 에서 28*28*3 텐서로 변환\n",
    "    \n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c269bffc-2960-4df1-bca9-94d987c28004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making Discriminator\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape = img_shape, padding='same')) # img 받고 14*14*32 텐서로 변환\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same')) # 14*14*32에서 7*7*64 텐서로 변환\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same')) # 7*7*64 에서 3*3*128 텐서로 변환\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d80c4d-6c32-47e0-97ad-ac63a007739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 17:10:02.865141: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-04 17:10:02.865223: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 32, 32, 3)\n\nCall arguments received by layer \"sequential\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m G \u001b[38;5;241m=\u001b[39m build_generator(z_dim)\n\u001b[1;32m     14\u001b[0m D\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m gan \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mAdam())\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mbuild_gan\u001b[0;34m(G, D)\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(G)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/input_spec.py:248\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    246\u001b[0m       value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape_as_list[\u001b[38;5;28mint\u001b[39m(axis)] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {value, \u001b[38;5;28;01mNone\u001b[39;00m}:\n\u001b[0;32m--> 248\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    249\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    250\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    251\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbut received input with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 32, 32, 3)\n\nCall arguments received by layer \"sequential\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "def build_gan(G, D):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(G)\n",
    "    model.add(D)\n",
    "    \n",
    "    return model\n",
    "\n",
    "D = build_discriminator(img_shape)\n",
    "D.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "G = build_generator(z_dim)\n",
    "\n",
    "D.trainable = False\n",
    "\n",
    "gan = build_gan(G, D)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cc8ea03-de9f-436a-99fe-bbcebc735fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "acc = []\n",
    "checkpoint = []\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "    (x_train, _), (_,_) = cifar10.load_data()\n",
    "    assert x_train.shape == (50000, 32, 32, 3)\n",
    "    x_train = x_train / 127.5 - 1.0  # [0:255] 흑백 픽셀 값을 [-1:1]로 스케일 조정\n",
    "    x_train = np.expand_dims(x_train, axis=3)\n",
    "    \n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "        imgs = x_train[idx]\n",
    "        \n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = G.predict(z)\n",
    "        \n",
    "        d_loss_real = D.train_on_batch(imgs, real)\n",
    "        d_loss_fake = D.train_on_batch(gen_imgs, fake)\n",
    "        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = G.predict(z)\n",
    "        \n",
    "        g_loss = gan.train_on_batch(z, real)\n",
    "        \n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            loss.append((d_loss, g_loss))\n",
    "            acc.append(100.0 * accuracy)\n",
    "            checkpoint.append(iteration + 1)\n",
    "            \n",
    "            print(\"{} D loss : {}, acc : {}, G loss : {}\".format(iteration+1, d_loss, 100.0*accuracy, g_loss))\n",
    "            \n",
    "            sample_images(G)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19aa2b1d-bbdc-4a78-b987-164f33d09c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(G, image_grid_rows=4, image_grid_col=4):\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_col, z_dim))\n",
    "    \n",
    "    gen_imgs = G.predict(z)\n",
    "    \n",
    "    gen_imgs = 0.5 + gen_imgs + 0.5 # 이미지 픽셀 값을 [0:1] 범위로 스케일 조정\n",
    "    \n",
    "    fig, axs = plt.subplots(image_grid_rows, image_grid_col, figsize=(4,4), sharey=True, sharex=True)\n",
    "    cnt = 0 \n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_col):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c698510a-e441-43e2-a7cb-4c189cf79cde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 1024), found shape=(32, 100)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      3\u001b[0m sample_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_interval\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(iterations, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     16\u001b[0m imgs \u001b[38;5;241m=\u001b[39m x_train[idx]\n\u001b[1;32m     18\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (batch_size, \u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m gen_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m D\u001b[38;5;241m.\u001b[39mtrain_on_batch(imgs, real)\n\u001b[1;32m     22\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m D\u001b[38;5;241m.\u001b[39mtrain_on_batch(gen_imgs, fake)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/zk/k32fdmz950df1vp1p0prwclm0000gn/T/__autograph_generated_filentm8zjaj.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/imjun-yeob/miniconda3/envs/tensorflow-dev/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 1024), found shape=(32, 100)\n"
     ]
    }
   ],
   "source": [
    "iterations = 20000\n",
    "batch_size = 128\n",
    "sample_interval = 1000\n",
    "\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e020df1-3902-40b2-a0c6-b364eed5cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
